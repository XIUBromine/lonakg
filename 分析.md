uid节点目前有以下属性：

| 属性             | 值                   |
| ---------------- | -------------------- |
| blacklist_reason | A003,B001            |
| status           | blacklisted          |
| uid_key          | 20190620023153883082 |

现在我想对所有blacklisted的uid节点进行数据分析，思路是这样的：

从黑名单uid节点出发，统计k跳关联的所有“异常节点”，这里的异常节点包括：

- 其他blacklisted的节点（uid、phone_num、identity_no节点）
- 非uid节点的associated_uid_count>1即为一个"异常节点"

返回的结果是一个列表，列表中的每个元素格式如下：

```
{
	"type": "blacklisted"/"common",	//用来标记这个节点是不是黑名单节点
	"label": "uid"/"phone_num"/"remote_ip"...,	//用来标记节点所属类型
	"associated_uid_count": n	//该异常节点关联的uid数，uid类型的异常节点没有这个属性，设置为0
}
```

对所有blacklisted的uid节点的”异常节点“列表进行数据分析，并与非blacklisted的uid节点的”异常节点“列表数据特征进行对比



实现上述数据分析/对比的脚本







你实现的脚本目前有以下问题不符合我的预期：

- 分析的维度应该从【单个uid节点关联的异常节点】出发，而不是从“全体黑名单uid”/“全体正常uid”出发，具体到代码层面，analyze_uid_group中

  ```python
  anomaly_nodes = self.find_anomaly_nodes_k_hop(session, uid, k)
  all_anomaly_nodes.extend(anomaly_nodes)
  ```

  这段代码肯定不对，extend将使得无法区分anomaly_nodes对应的是哪个uid节点

  因为我整体的思路是：

  从uid节点出发，计算k度关联的异常节点。可以为每类节点/每跳设置不同的权重w，例如已知的黑名单uid节点影响权重最大。最终根据这些k度关联的异常节点得到uid节点的风险分数，再设置一定的阈值δ，超过该阈值就判断这个节点是黑名单节点，通过调整上面的超参数k，Δ，w，δ来验证算法能不能将黑名单节点识别出来，识别的准确率、精准率、召回率、AUC是多少

  因此你的分析应该从【单个uid节点关联的异常节点】出发

  



你先不要实现具体的风险计算，你只需要对数据进行分析，我想要的分析结果形如：

每个黑名单节点的邻域“异常节点”特征：

- 1-hop：

  平均异常节点数

  每类异常节点（黑名单uid、黑名单phone_num、黑名单identity_no、异常phone_num、异常identity_no、...）的数量分布情况，以及这些异常节点关联的uid数量的分布情况

- 2-hop：

  ...

- 3-hop:

  ...

普通节点也是上面的分析方法





共计327个黑名单节点：

- 孤立黑名单节点（在3跳之内不与其他异常节点关联）：276

  51个







500个普通节点：

- 孤立普通节点：143





91个黑名单节点：

- 孤立黑名单节点：18



5000个普通节点

- 鼓励普通节点：1830