"""
é»‘åå•uidèŠ‚ç‚¹å…³è”å¼‚å¸¸èŠ‚ç‚¹åˆ†æè„šæœ¬

è¯¥è„šæœ¬åˆ†æblacklisted uidèŠ‚ç‚¹çš„kè·³å…³è”å¼‚å¸¸èŠ‚ç‚¹ç‰¹å¾ï¼Œå¹¶ä¸æ­£å¸¸uidèŠ‚ç‚¹è¿›è¡Œå¯¹æ¯”ã€‚

å¼‚å¸¸èŠ‚ç‚¹å®šä¹‰ï¼š
1. blacklistedçŠ¶æ€çš„èŠ‚ç‚¹ï¼ˆuidã€phone_numã€identity_noï¼‰
2. éuidèŠ‚ç‚¹çš„associated_uid_count > 1

åˆ†æç»´åº¦ï¼š
- å¼‚å¸¸èŠ‚ç‚¹æ•°é‡åˆ†å¸ƒ
- å¼‚å¸¸èŠ‚ç‚¹ç±»å‹åˆ†å¸ƒ
- å…³è”åº¦åˆ†å¸ƒ
- kè·³è·ç¦»åˆ†æ
"""
import json
from typing import Dict, List, Any, Set, Tuple
from dataclasses import dataclass

from neo4j import GraphDatabase, Session
from dotenv import load_dotenv
import os
from sklearn.metrics import roc_auc_score, classification_report
import numpy as np

# åŠ è½½Neo4jè¿æ¥ä¿¡æ¯
load_dotenv()
NEO4J_URI = os.getenv("NEO4J_URI", "bolt://localhost:7687")
NEO4J_USER = os.getenv("NEO4J_USER", "neo4j")
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD", "123456")

# æ‰€æœ‰èŠ‚ç‚¹ç±»å‹
ALL_NODE_LABELS = [
    "uid",
    "phone_num",
    "identity_no",
    "card_no",
    "device_no",
    "td_device_id",
    "remote_ip",
    "geo_code",
]

# å¯èƒ½æœ‰é»‘åå•çŠ¶æ€çš„èŠ‚ç‚¹ç±»å‹
BLACKLISTABLE_LABELS = ["uid", "phone_num", "identity_no"]


@dataclass
class AnomalyNode:
    """å¼‚å¸¸èŠ‚ç‚¹æ•°æ®ç»“æ„"""

    node_type: str  # blacklisted æˆ– anomalous
    label: str  # èŠ‚ç‚¹æ ‡ç­¾
    associated_uid_count: int  # å…³è”uidæ•°é‡
    hop_distance: int  # è·³æ•°è·ç¦»
    node_key: str = ""  # èŠ‚ç‚¹keyï¼ˆç”¨äºå»é‡ï¼‰


class AnomalyDetection:
    """é»‘åå•é‚»åŸŸåˆ†æå™¨"""

    def __init__(self, max_k_hops: int = 3, weights=None):
        self.driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))
        self.max_k_hops = max_k_hops
        self.weights = weights

    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        self.driver.close()

    def get_risk_score(self, session: Session, uid_key: str) -> float:
        """åˆ†æå•ä¸ªuidçš„é‚»åŸŸå¼‚å¸¸èŠ‚ç‚¹"""

        # ä¸€æ¬¡æ€§è·å–æ‰€æœ‰kè·³çš„å¼‚å¸¸èŠ‚ç‚¹
        all_anomaly_nodes = self.find_anomaly_nodes_k_hop(
            session, uid_key, self.max_k_hops
        )

        risk_score = 0
        for node in all_anomaly_nodes:
            # æ„å»ºæƒé‡é”®ï¼šnode_type + "_" + label
            weight_key = f"{node.node_type}_{node.label}"
            hop_weights = self.weights[node.hop_distance - 1]
            weight = hop_weights.get(weight_key, 0)
            if weight_key == "blacklisted_uid":
                risk_score += weight
            else:
                risk_score += weight * (node.associated_uid_count - 1)

        return risk_score


    def find_anomaly_nodes_k_hop(
        self, session: Session, start_uid: str, k: int = 3
    ) -> List[AnomalyNode]:
        """æŸ¥æ‰¾ä»æŒ‡å®šuidå¼€å§‹kè·³å†…çš„æ‰€æœ‰å¼‚å¸¸èŠ‚ç‚¹"""

        # æ„å»ºkè·³æŸ¥è¯¢
        # è¿™é‡Œä½¿ç”¨å˜é•¿è·¯å¾„æŸ¥è¯¢ï¼Œé™åˆ¶æœ€å¤§è·³æ•°
        query = f"""
        MATCH (start:uid {{uid_key: $start_uid}})
        MATCH path = (start)-[*1..{k}]-(n)
        WHERE labels(n)[0] IN $all_labels AND n <> start
        WITH DISTINCT n, length(path) as hop_distance
        
        // æ£€æŸ¥æ˜¯å¦ä¸ºå¼‚å¸¸èŠ‚ç‚¹
        WITH n, hop_distance,
             CASE 
                 WHEN labels(n)[0] IN $blacklistable_labels AND n.status = 'blacklisted' THEN 'blacklisted'
                 WHEN labels(n)[0] <> 'uid' AND n.associated_uid_count > 1 THEN 'anomalous'
                 ELSE 'normal'
             END as node_type

        WHERE node_type IN ['blacklisted', 'anomalous']
        
        RETURN 
            node_type,
            labels(n)[0] as label,
            COALESCE(n.associated_uid_count, 0) as associated_uid_count,
            hop_distance,
            CASE 
                WHEN labels(n)[0] = 'uid' THEN n.uid_key
                ELSE n.key
            END as node_key
        ORDER BY hop_distance, node_type, label
        """

        result = session.run(
            query,
            start_uid=start_uid,
            all_labels=ALL_NODE_LABELS,
            blacklistable_labels=BLACKLISTABLE_LABELS,
        )

        anomaly_nodes = []
        seen_nodes = set()  # ç”¨äºå»é‡

        for record in result:
            node_key = f"{record['label']}_{record['node_key']}"
            if node_key not in seen_nodes:
                seen_nodes.add(node_key)

                anomaly_nodes.append(
                    AnomalyNode(
                        node_type=record["node_type"],
                        label=record["label"],
                        associated_uid_count=record["associated_uid_count"],
                        hop_distance=record["hop_distance"],
                        node_key=node_key,
                    )
                )

        return anomaly_nodes

def main():
    """ä¸»å‡½æ•°"""
    MAX_K_HOPS = 3
    weights = [
        # 1è·³æƒé‡
        {
            "blacklisted_phone_num": 1,
            "blacklisted_identity_no": 1,
            "anomalous_phone_num": 1,
            "anomalous_identity_no": 1,
            "anomalous_card_no": 1,
            "anomalous_device_no": 1,
            "anomalous_td_device_id": 1,
            "anomalous_remote_ip": 1,
            "anomalous_geo_code": 1
        },
        # 2è·³æƒé‡
        {
            "blacklisted_uid": 10
        },
        # 3è·³æƒé‡
        {
            "blacklisted_phone_num": 10,
            "blacklisted_identity_no": 10,
            "anomalous_phone_num": 0.1,
            "anomalous_identity_no": 0.1,
            "anomalous_card_no": 0.1,
            "anomalous_device_no": 0.1,
            "anomalous_td_device_id": 0.1,
            "anomalous_remote_ip": 0.1,
            "anomalous_geo_code": 0.1
        },
    ]

    model = AnomalyDetection(max_k_hops=MAX_K_HOPS, weights=weights)

    try:
        with model.driver.session() as session:
            # è¯»å–é»‘åå•å’Œæ­£å¸¸uid
            with open("data_analysis/normal_user_ids.txt", "r", encoding="utf-8") as f:
                normal_uids = [line.strip() for line in f if line.strip()]
            with open(
                "data_analysis/blacklist_user_ids.txt", "r", encoding="utf-8"
            ) as f:
                blacklist_uids = [line.strip() for line in f if line.strip()]

            print(f"ğŸ“Š å¼€å§‹åˆ†æ {len(normal_uids)} ä¸ªæ­£å¸¸ç”¨æˆ·å’Œ {len(blacklist_uids)} ä¸ªé»‘åå•ç”¨æˆ·")
            
            risk_scores = []
            true_labels = []
            uids_list = []
            
            # å¤„ç†é»‘åå•ç”¨æˆ·ï¼ˆæ ‡ç­¾ä¸º1ï¼‰
            print("ğŸ” åˆ†æé»‘åå•ç”¨æˆ·...")
            for i, uid in enumerate(blacklist_uids):
                risk_score = model.get_risk_score(session, uid)
                risk_scores.append(risk_score)
                true_labels.append(1)  # é»‘åå•ç”¨æˆ·æ ‡ç­¾ä¸º1
                uids_list.append(uid)
                if (i + 1) % 100 == 0:
                    print(f"  å·²å¤„ç†é»‘åå•ç”¨æˆ·: {i + 1}/{len(blacklist_uids)}")
                print(f"UID: {uid}, Status: blacklisted, Risk Score: {risk_score}")
            
            # å¤„ç†æ­£å¸¸ç”¨æˆ·ï¼ˆæ ‡ç­¾ä¸º0ï¼‰
            print("ğŸ” åˆ†ææ­£å¸¸ç”¨æˆ·...")
            for i, uid in enumerate(normal_uids):
                risk_score = model.get_risk_score(session, uid)
                risk_scores.append(risk_score)
                true_labels.append(0)  # æ­£å¸¸ç”¨æˆ·æ ‡ç­¾ä¸º0
                uids_list.append(uid)
                if (i + 1) % 100 == 0:
                    print(f"  å·²å¤„ç†æ­£å¸¸ç”¨æˆ·: {i + 1}/{len(normal_uids)}")
                print(f"UID: {uid}, Status: normal, Risk Score: {risk_score}")
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            risk_scores = np.array(risk_scores)
            true_labels = np.array(true_labels)
            
            print(f"\nğŸ“ˆ æ¨¡å‹è¯„ä¼°ç»“æœ:")
            print(f"æ€»æ ·æœ¬æ•°: {len(risk_scores)}")
            print(f"æ­£æ ·æœ¬æ•°ï¼ˆé»‘åå•ï¼‰: {sum(true_labels)}")
            print(f"è´Ÿæ ·æœ¬æ•°ï¼ˆæ­£å¸¸ç”¨æˆ·ï¼‰: {len(true_labels) - sum(true_labels)}")
            
            # è®¡ç®—AUC
            if len(set(true_labels)) > 1:  # ç¡®ä¿æœ‰ä¸¤ç§æ ‡ç­¾
                auc_score = roc_auc_score(true_labels, risk_scores)
                print(f"ğŸ¯ AUC Score: {auc_score:.4f}")
                
                # æ˜¾ç¤ºé£é™©åˆ†æ•°ç»Ÿè®¡
                print(f"\nğŸ“Š é£é™©åˆ†æ•°ç»Ÿè®¡:")
                print(f"é»‘åå•ç”¨æˆ·é£é™©åˆ†æ•° - å‡å€¼: {np.mean(risk_scores[true_labels==1]):.4f}, "
                      f"æ ‡å‡†å·®: {np.std(risk_scores[true_labels==1]):.4f}")
                print(f"æ­£å¸¸ç”¨æˆ·é£é™©åˆ†æ•° - å‡å€¼: {np.mean(risk_scores[true_labels==0]):.4f}, "
                      f"æ ‡å‡†å·®: {np.std(risk_scores[true_labels==0]):.4f}")
                
                # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
                results = {
                    'auc_score': float(auc_score),
                    'total_samples': len(risk_scores),
                    'positive_samples': int(sum(true_labels)),
                    'negative_samples': int(len(true_labels) - sum(true_labels)),
                    'blacklist_risk_mean': float(np.mean(risk_scores[true_labels==1])),
                    'blacklist_risk_std': float(np.std(risk_scores[true_labels==1])),
                    'normal_risk_mean': float(np.mean(risk_scores[true_labels==0])),
                    'normal_risk_std': float(np.std(risk_scores[true_labels==0])),
                    'weights': weights
                }
                
                with open("model/evaluation_results.json", "w", encoding="utf-8") as f:
                    json.dump(results, f, ensure_ascii=False, indent=2)
                print(f"ğŸ“ è¯„ä¼°ç»“æœå·²ä¿å­˜åˆ° model/evaluation_results.json")
                
                # ä¿å­˜è¯¦ç»†é¢„æµ‹ç»“æœ
                detailed_results = []
                for i, (uid, true_label, risk_score) in enumerate(zip(uids_list, true_labels, risk_scores)):
                    detailed_results.append({
                        'uid': uid,
                        'true_label': int(true_label),
                        'risk_score': float(risk_score),
                        'status': 'blacklisted' if true_label == 1 else 'normal'
                    })
                
                with open("model/detailed_predictions.json", "w", encoding="utf-8") as f:
                    json.dump(detailed_results, f, ensure_ascii=False, indent=2)
                print(f"ğŸ“ è¯¦ç»†é¢„æµ‹ç»“æœå·²ä¿å­˜åˆ° model/detailed_predictions.json")
                
            else:
                print("âš ï¸  è­¦å‘Š: åªæœ‰ä¸€ç§æ ‡ç­¾ï¼Œæ— æ³•è®¡ç®—AUC")
            

    except Exception as e:
        print(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        raise

    finally:
        model.close()


if __name__ == "__main__":
    main()
